<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>16-886: Interactive Robotics</title>
  
  <meta name="author" content="Andrea Bajcsy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Style-related -->
  <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="favicon-dragon.ico">
  <!--/ Style-related -->

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
  </script>
  <script>
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <!--/ MathJax -->
</head>


<!-- HEADER -->
<div class="header" style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-bottom:0px;">
  <!-- Class name -->
  <a href="index.html" class="logo" style="color:black;font-size:30px; padding-top:30px; padding-left:0px; width:100%;max-width:900px;">16-886 Models & Algorithms for Interactive Robotics<p>Spring 2024</p></a>
</div>
<!--/ HEADER -->


<body>

<!-- CONTENT -->
<table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr style="padding:0px">
    <td style="padding:0px" class=main>
    
  <img src="./static/images/front_fig.png" class="center" width=100%>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
    <tr>
      <td class=main>

        <p>
          <b>Professor:</b> <a href="https://www.cs.cmu.edu/~abajcsy/">Andrea Bajcsy</a>  (<tt>abajcsy [at] cmu [dot] edu</tt>)
        </p>
        <p>
          <b>Time: </b> Mon & Wed, 11:00 - 12:20pm
          <br>
          <b>Location: </b> NSH 3002
        </p>
        <p>
          <b>Syllabus: </b> <a href="16_886_syllabus.pdf">PDF</a>
        </p>

        <h1 style="font-variant-caps: small-caps;">Overview</h1>
        <p>
          Robot deployment around real people is rapidly accelerating: autonomous cars navigate through crowded cities on a daily basis, assistive robots increasingly help end-users with daily living tasks, and large teams of human engineers interactively teach robots basic skills. However, robot interaction with humans requires us to re-evaluate the assumptions built into all components of our autonomy algorithms, from decision-making, to machine learning, to safety analysis.
        </p>
        <p>
          In this graduate seminar class, we will build the mathematical foundations for modeling human-robot interaction, develop the tools to analyze the safety and reliability of robots deployed around people, and investigate algorithms for robot learning from human data. The approaches covered will draw upon a variety of tools such as optimal control, dynamic game theory, Bayesian inference, and modern machine learning. Throughout the class, there will also be guest lectures from experts in the field. Students will practice essential research skills including reviewing papers, writing research project proposals, and technical communication.
        </p>

        <h1 style="font-variant-caps: small-caps;">Prerequisites</h1>
        <p>
          The course is open to graduate students without strict prerequisites. Familiarity with differential equations, probability, and linear algebra is highly encouraged. Interested undergraduate students with a strong background may seek approval from the instructor.
        </p>
        <!------------------------------------------->
      </td>
    </tr>
  </tbody>
  </table>
  <!--/ CONTENT -->

  <!-- SCHEDULE -->
 
  <h1 style="font-variant-caps: small-caps;">
    Schedule (tentative)
  </h1>
  <table style="width:100%" class=schedule>
  <tr>
    <th>Date</th>
    <th>Topic</th>
    <th>Info</th>
    <!-- <th>Info</th> -->
  </tr>
  
<!--------------------->
 <tr class="block"> 
    <td><b>Week 1</b> <br> Mon, Jan 15</td>
    <td><i>No Class (MLK Day)</i></td>
    <td>
    </td>
    <!-- <td> </td> -->
  </tr>

  <tr class="block">
    <td><b>Week 1</b> <br> Wed, Jan 17</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Introduction</td>
    <td>
      <ul>
        <li> Please check the course syllabus </li>
        <li> Please sign up for 3 presenter slots by Monday Jan 22 </li>
      </ul>
    </td>
    <!-- <td></td> -->
  </tr>
<!--------------------->
  <tr> 
    <td><b>Week 2</b> <br> Mon, Jan 22</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Dynamical systems model of interaction</td>
    <td> <i><span class="label label-due text-base">Due</span></i> <b>Presentation Sign-up</b>
      <!-- <ul>
        <li>A systems model of interaction</li>
        <li>Preview of the course topics through this lens</li>
      </ul> -->
    </td>
    <!-- <td> Sign up for presentations</i> </td> -->
  </tr>

  <tr>
    <td><b>Week 2</b> <br> Wed, Jan 24</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Refresh: optimal decision-making </td>
    <td> 
      <!-- <ul>
        <li></li>
      </ul> -->
    </td>
    <!-- <td> </td> -->
  </tr>

<!--------------------->
  <tr class="block">
    <td><b>Week 3</b> <br> Mon, Jan 29</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Safety Analysis I </td>
    <td> <i>Further reading:</i>
      <ul>
        <li>A Time-Dependent Hamilton–Jacobi Formulation of Reachable Sets for Continuous Dynamic Games, Mitchell et al. (2005)</li>
        <li>Hamilton-Jacobi formulation for reach-avoid differential games, Margellos & Lygeros (2009)</li>
        <li>Reach-avoid problems with time-varying dynamics, targets and constraints, Fisac et al. (2015)</li>
        <li>Hamilton-Jacobi Reachability: A Brief Overview and Recent Advances, Bansal et al. (2017) </li>
      </ul>
    </td>
    <!-- <td> </td> -->
  </tr>
  
 <tr class="block">
    <td><b>Week 3</b> <br> Wed, Jan 31</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Safety Analysis II </td>
    <td> <i>HW 1 Released</i>
      <!-- <ul>
        <li>Imitation learning, BC </li>
        <li>DAgger & Variants</li>
      </ul> -->
    </td>
    <!-- <td> <i>HW 1 Released</i> </td> -->
  </tr>

   <!--------------------->
   <tr>
    <td><b>Week 4</b> <br> Mon, Feb 5</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Multi-agent Safety I</td>
    <td> 
      <i><span class="label label-due text-base">Due</span></i> <b>Project Proposal</b>
      <!-- <ul>
        <li>Physical corrections </li>
        <li>Preferences, rankings</li>
        <li>RRIC, language, gestures</li>
      </ul> -->
    </td>
    <!-- <td>  </td> -->
  </tr>


 <tr>
    <td><b>Week 4</b> <br> Wed Feb 7</td>
    <td><i><span class="label label-presentation text-base">Paper discussion</span></i> Multi-agent Safety II</td>
    <td> 
      <ul>
        <li> Safety Assurances for Human-Robot Interaction via Confidence-aware Game-theoretic Human Models. Tian, et al. (2022) </li>
        <li> Towards the Unification and Data-Driven Synthesis of Autonomous Vehicle Safety Concepts. Leung & Bajcsy, et al. (2022) </li>
      </ul>
    <!-- <td></td> -->
  </tr>

   <!--------------------->
   <tr class="block"> 
    <td><b>Week 5</b> <br> Mon, Feb 12</td>
    <td><i><span class="label label-presentation text-base">Paper discussion</span></i> Computationally scalable safety</td>
    <td> 
      <ul>
        <li>Reachability-Based Safety Guarantees using Efficient Initializations. Herbert, et al. (2019)</li>
        <li>DeepReach: A Deep Learning Approach to High-Dimensional Reachability. Bansal & Tomlin (2020)</li>
        <li>ISAACS: Iterative Soft Adversarial Actor-Critic for Safety. Hsu, et al. (2023)</li>
        <li> Parameter-Conditioned Reachable Sets for Updating Safety Assurances Online. Borquez, et al. (2023)</li>
      </ul>
    </td>
    <!-- <td> </td> -->
   </tr>

   
  <tr class="block"> 
    <td><b>Week 5</b> <br> Wed, Feb 14</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Safety filtering & planning </td>
    <td> <i><span class="label label-due text-base">Due</span></i> <b>HW 1 </b> 
      <p><i>Further Reading:</i></p>
      <ul>
        <li>An Efficient Reachability-Based Framework for Provably Safe Autonomous Navigation in Unknown Environments. Bajcsy, et al. (2019)</li>
        <li>Data-Driven Safety Filters: Hamilton-Jacobi Reachability, Control Barrier Functions, and Predictive Methods for Uncertain Systems. Wabersich, et al. (2023)</li>
        <li>The safety filter: A unified view of safety-critical control in autonomous systems. Hsu, et al. (2023)</li>
      </ul>
    </td>
    <!-- <td>  </td> -->
  </tr>

   <!--------------------------->

   <tr>
    <td><b>Week 6</b> <br> Mon, Feb 19</td>
    <td><i><span class="label label-presentation text-base">Paper discussion</span></i> Safe robot learning</td>
    <td> 
      <ul>
        <li>Constrained policy optimization. Achiam, et al. (2017)</li>
        <li> A general safety framework for learning-based control in uncertain robotic systems. Fisac, et al. (2018)</li>
        <!-- <li> Conservative safety critics for exploration. Bharadhwaj, et al. (2020).</li>-->
        <li>Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning. Brunke, et al. (2021)</li>
        <li> Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy. Hu & Zhang, et al. (2023)</li>
      </ul>
    </td>
    <!-- <td> </td> -->
   </tr>

   
 <tr>
    <td><b>Week 6</b> <br> Wed, Feb 21</td>
    <td><i><span class="label label-presentation text-base">Paper discussion</span></i>  Latent-space & human-centered safety concepts</td>
    <td> 
      <ul>
        <li> Analyzing Human Models that Adapt Online. Bajcsy, et al. (2021)</li>
        <li> LS3: Latent Space Safe Sets for Long-Horizon Visuomotor Control of Sparse Reward Iterative Tasks. Wilcox & Balakrishna, et al. (2021)</li>
        <li> Learning autonomous vehicle safety concepts from demonstrations. Leung, et al. (2023)</li>
        <li> Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners. Ren, et al. (2023)</li>
      </ul>
    </td>
    <!-- <td> </td> -->
  </tr>

   <!--------------------------->
   <tr class="block">
    <td><b>Week 7</b> <br> Mon, Feb 26</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Human behavior prediction</td>
    <td> 
      <ul>
        <li>Activity Forecasting, Kitani et al. (2012)</li>
        <li> Confidence-aware motion prediction for real-time collision avoidance, Fridovich-Keil & Bajcsy et al (2019) </li>
        <li>Identifying Driver Interactions via Conditional Behavior Prediction, Tolstaya et al. (2021) </li>
        <li>MotionLM: Multi-Agent Motion Forecasting as Language Modeling, Seff et al. (2023)</li>
      </ul>
    </td>
    <!-- <td> </td> -->
   </tr>
    
 <tr class="block">
    <td><b>Week 7</b> <br> Wed, Feb 28</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Game-theoretic models of multi-agent interaction</td>
    <td><i>HW 2 Released</i> <p> <i> Further Reading</i></p>
      <ul>
        <li> Planning for Cars that Coordinate with People: Leveraging Effects on Human Actions for Planning and Active Information Gathering over Human Internal State. Sadigh et al. (2018)</li>
        <li> Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games, Fridovich-Keil et al. (2019)</li>
        <li> NashFormer: Leveraging Local Nash Equilibria for Semantically Diverse Trajectory Prediction, Lidard et al. (2023)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 
    <!--------------------------->     

 <tr>
    <td><b>Week 8</b> <br> Mon, Mar 4</td>
    <td><i>No Class (Spring Break)</i></td>
    <td></td>
    <!-- <td></td> -->
 </tr>

 <tr>
    <td><b>Week 8</b> <br> Wed, Mar 6</td>
    <td><i>No Class (Spring Break)</i></td>
    <td></td>
    <!-- <td></td> -->
 </tr>
 
    <!--------------------------->   
 <tr class="block">
    <td><b>Week 9</b> <br> Mon, Mar 11</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Learning from demonstration </td>
    <td> <i>Further Reading:</i>
      <ul>
        <li> Maximum Entropy IRL, Ziebart et al. (2010) </li>
        <li> Maximum Margin Planning, Ratliff et al. (2006) </li>
        <li> Maximum Entropy Deep Inverse Reinforcement Learning, Wulfmeier et al. (2016) </li>
        <li> Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap, Swamy et al. (2021)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 </tr>

 <!--       <ul>
        <li>"Planning Based Prediction for Pedestrians" (2009) </li>
        <li>"Goal Inference as Invese Planning" (2007)</li>
        <li>"Obsessed with Goals" (2007)</li>
        <li><a href = 'https://arxiv.org/abs/2008.08294'>TNT: Target-driveN Trajectory Prediction</a> (2020)</li>
      </ul> -->


 <tr class="block">
    <td><b>Week 9</b> <br> Wed, Mar 13</td>
    <td><i><span class="label label-guest-lecture text-base">Guest lecture</span></i> Prof. David Fridovich-Keil</td>
    <td>
      <!-- <p><b>Talk Title</b><i>: "Imitation Learning: It's only a game!"</i><p> -->
        <p><b>Talk Theme</b><i>: Multi-agent reward learning</i><p>
    </td>
 </tr>
 
  <!--------------------------->   
<tr>
    <td><b>Week 10</b> <br> Mon, Mar 18</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Optimal teaching & active learning </td>
    <td> <i><span class="label label-due text-base">Due</span></i> <b>HW 2</b> 
      <p> <i> Further Reading: </i></p>
      <ul>
        <li> Algorithmic and human teaching of sequential decision tasks. Cakmak and Lopes (2012)</li>
        <li> Pragmatic-Pedagogic Value Alignment. Fisac, et al. (2016)</li>
        <li> Batch Active Preference-Based Learning of Reward Functions. Biyik & Sadigh (2018)</li>
      </ul>
    </td>
  </tr>
 </tr>

 <tr>
    <td><b>Week 10</b> <br> Wed, Mar 20</td>
    <td><i><span class="label label-presentation text-base">Paper discussions</span></i> Learning from sub-optimal demonstration data</td>
    <td>
      <ul>
        <li>Better-than-demonstrator Imitation Learning via Automatically-ranked Demonstrations. Brown, et al. (2020)</li>
        <li>Learning from Suboptimal Demonstration via Self-Supervised Reward Regression. Chen et al. (2020)</li>
        <li>Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality. Zhang and Cao. (2021)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 
  <!--------------------------->   
   <tr class="block">
    <td><b>Week 11</b> <br> Mon, Mar 25</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Sources of human feedback</td>
    <td>
      <ul>
        <li> Learning robot objectives from physical human interaction, Bajcsy et al. (2018) </li>
        <li> Reward-rational (implicit) choice: A unifying formalism for reward learning, Jeon et al. (2020)</li>
        <li> Learning Generalizable Robotic Reward Functions from “In-The-Wild” Human Videos, Chen et al. (2021) </li>
        <li> Correcting Robot Plans with Natural Language Feedback, Sharma et al. (2022)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>

 <tr class="block">
    <td><b>Week 11</b> <br> Wed, Mar 27</td>
    <td><i><span class="label label-presentation text-base">Paper discussions</span></i> Reinforcement learning from human feedback</td>
    <td>
      <ul>
        <li><a href="https://arxiv.org/abs/1706.03741">Deep reinforcement learning from human preferences</a>. Christiano et al. (2017)</li>
        <li><a href="https://arxiv.org/abs/2310.13639">Contrastive Preference Learning: Learning from Human Feedback without RL</a>. Hejna et al. (2023)</li>
        <li><a href="https://arxiv.org/abs/2307.15217">Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</a>. Capser et al. (2023)</li>
        <li><a href="https://arxiv.org/abs/2312.00886">Nash Learning from Human Feedback</a>. Munos et al. (2024)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 
  <!--------------------------->   
 <tr>
    <td><b>Week 12</b> <br> Mon, Apr 1</td>
    <td><i><span class="label label-guest-lecture text-base">Guest Lecture</span></i> Prof. Sanjiban Choudhury </td>
    <td><span class="label label-due text-base">Due</span> </i> <b>Mid-term Report </b>
      <p><b>Talk Title</b><i>: "Imitation Learning: It's only a game!"</i><p>
    </td>
    <!-- <td></td> -->
 </tr>

 <tr>
    <td><b>Week 12</b> <br> Wed, Apr 3</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Repeated interactions, coordination, and influence</td>
    <td>
      <ul>
        <li> Formalizing Human-Robot Mutual Adaptation: A Bounded Memory Model. Nikolaidis, et al. (2014) </li>
        <li> On the Utility of Learning about Humans for Human-AI Coordination. Carroll, et al. (2019)</li>
        <li> Learning Latent Representations to Influence Multi-Agent Interaction. Xie, et al. (2020) </li>
        <li> Towards Modeling and Influencing the Dynamics of Human Learning. Tian, et al. (2023) </li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 
   <!--------------------------->   
 <tr class="block">
    <td><b>Week 13</b> <br> Mon, Apr 8</td>
    <td><i><span class="label label-presentation text-base">Paper discussions</span></i>  Shared autonomy </td>
    <td>
      <ul>
        <li>Shared Autonomy via Deep Reinforcement Learning. Reddy, et al. (2018)</li>
        <li>Scaled Autonomy: Enabling Human Operators to Control Robot Fleets, Swamy et al. (2020)</li>
        <li>LILA: Language-Informed Latent Actions. Karamcheti and Srivastava et al. (2021)</li>
        <li>Learning to share autonomy across repeated interaction. Jonnavittula and Losey. (2021)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>


 <tr class="block">
    <td><b>Week 13</b> <br> Wed, Apr 10</td>
    <td> <i><span class="label label-lecture text-base">Lecture</span></i> Reward specification challenges</td>
    <td>
      <ul>
        <li>Quantifying Hypothesis Space Misspecification in Learning from Human-Robot Demonstrations and Physical Corrections. Bobu et al. (2020)</li>
        <li>Inverse Reward Design. Hadfield-Menell et al. (2020)</li>
        <li>The effects of reward misspecification: Mapping and mitigating misaligned models. Pan et al. (2022)</li>
        <li>Goal Misgeneralization in Deep Reinforcement Learning. Langosco et al. (2023)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>
 
  <!--------------------------->   
 <tr>
    <td><b>Week 14</b> <br> Mon, Apr 15</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Representation learning</td>
    <td>
      <ul>
        <li> Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration. Bullard, et al. (2018)</li>
        <li> Feature Expansive Reward Learning: Rethinking Human Input. Bobu, et al. (2021) </li>
        <li> People construct simplified mental representations to plan. Ho, et al. (2022)</li>
        <li> Learning invariant representations for reinforcement learning without reconstruction. Zhang et al. (2021)</li>
        <li> Language-Driven Representation Learning for Robotics. Karametchi, et al. (2023)</li> <!-- <a href="https://arxiv.org/abs/2302.12766"> -->
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>

 <tr>
    <td><b>Week 14</b> <br> Wed, Apr 17</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> Alignment</td>
    <td>
      <ul>
        <li> Scalable agent alignment via reward modeling: a research direction. Leike et al. (2018)</li>
        <li> Getting aligned on representational alignment, Sucholutsky et al. (2023)</li>
        <li> Diffusion Model Alignment Using Direct Preference Optimization, Wallace et al. (2023)</li>
        <li> What Matters to You? Towards Visual Representation Alignment for Robot Learning, Tian et al. (2023) </li>
        <li> AI Alignment: A Comprehensive Survey. Ji et al. (2023)</li>
      </ul>
    </td>
    <!-- <td></td> -->
 </tr>

 <!--------------------------->  
 
 <tr class="block">
    <td><b>Week 15</b> <br> Mon, Apr 22</td>
    <td><i><span class="label label-lecture text-base">Lecture</span></i> What <i>is</i> safety? AI Safety, OOD, and Risk in Robotics </td>
    <td>
      <ul>
        <li> How Should a Robot Assess Risk? Towards an Axiomatic Theory of Risk in Robotics, Majumdar & Pavone (2017)</li>
        <li> A System-Level View on Out-of-Distribution Data in Robotics, Sinha et al. (2022) </li>
      </ul>
    </td>
 </tr>

  <tr class="block">
    <td><b>Week 15</b> <br> Wed, Apr 24</td>
    <td><i><span class="label label-guest-lecture text-base">Guest Lecture</span></i> Prof. Aditi Raghunathan</td>
    <td> 
      <p><b>Talk Theme:</b> <i>ML Robustness</i></p>
    </td>
    <!-- <td></td> -->

 <!--------------------------->
  </tr>
    <td><b>Week 16</b> <br> Mon, Apr 29</td>
    <td><i><span class="label label-guest-lecture text-base">Guest Lecture</span></i> </td>
    <td> <i><span class="label label-due text-base">Due</span></i> <b>Slides on Apr. 30</b>
    </td>
    <!-- <td></td> -->
  </tr>


 <tr>
    <td><b>Week 16</b> <br> Wed, May 1</td>
    <td><i><span class="label label-presentation text-base">Final presentations</span></i> </td>
    <td></td>
    <!-- <td></td> -->
 </tr>
  
  <!--------------------------->   

 <tr class="block">
    <td><b>Week 17</b> <br> Mon, May 6</td>
    <td><i><span class="label label-presentation text-base">Final presentations</span></i> </td>
    <td><i><span class="label label-due text-base">Due</span></i> <b>Final report</b>
      
    </td>
    <!-- <td></td> -->
 </tr>

  <!--------------------------->   

</table>
  <!--/ SCHEDULE -->

  <!-- Footer -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0" style="padding-top:0px;">
    <tbody>
      <tr>
      <td class=main>
      <br>
      <p></p>
      <br><br>
      </td>
      </tr>
    </tbody>
  </table>
  <!--/ Footer -->

</body>

</html>
